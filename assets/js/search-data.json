{
  
    
        "post0": {
            "title": "Evaluation Metrics",
            "content": "In this notebook we are going to discuss about classificatio and regression metrics. Learning these metrics help in mastering the evaluation metrics concepts . 1. Classification Metrics 2. Regression Metrics . 1. Classification Metrics . There are different types of evaluation metrics in machine learning/deep learning and which metric to use depends on the dataset and also problem statement. Knowing when to use which metric is also an important job of Data Scientist. . | We are going to see the following metrics in details, their mathematics etc. . | . 1. Confusion Matrix a. Accuracy b. Precision c. Recall (Sensitivity) d. Specificity d. F1-Score 2. AUC-ROC . 1. Confusion Metric . Confusion matrix is the most commonly used metrics in machine learning or deep learning . The easiest way of understanding it is through diagrams. . | Before diving into diagrams, let us understand what it contains and how it represented. The confusion matrix mainly used for classification problems .i.e to identify predicted classes from actual classes. . | It mainly contain two outputs, one is actual outputs for all classes and the other is predicted outputs. Note that confusion matrix helps in measuring the correctness of our predicted classes from actual classes. . | Let us take an example of predicted whether a person is having a cancer(1) or not (0). Note, here 1 means positive and 0 means negative . | . Positive Negative . Positive | TP | FP | . Negative | FN | TN | . To understand more about confusion matrix, let us define what TP, FP etc. mean. . True Positives (TP):- . TP mean when the predicted class output and actual classes matches i.e. when the actual output is 1 and the predicted output is also 1 | . False Positives (FP):- . FP mean when the predicted class output and actual classes doesn&#39;t matches i.e. when the actual output is 0 and the predicted output is also 1 | . Flase Negatives (FN):- . FN mean when the predicted class output and actual classes doesn&#39;t matches i.e. when the actual output is 1 and the predicted output is also 0 | . True Negatives (TN):- . TN mean when the predicted class output and actual classes matches i.e. when the actual output is 0 and the predicted output is also 0 | . The ideal scenario should be that the model output 0 false positives and 0 false negatives. But that is not achievable in most of the real time scenarios. . a). Accuracy :- . Accuracy is number of correct prediction given by the model divided by the total number of predcitions. Lets us see it in different way, . | Accuracy = TP + TN/ TP+FP+FN+TN . | When to use Accuracy: . Accuracy is a good measure when the target variable classes in the data are nearly balanced. . | . b). Precision :- . Precision is a measure that tells us what proportion of patients that we diagnosed as having cancer, actually had cancer. The predicted positives (People predicted as cancerous are TP and FP) and the people actually having a cancer are TP. Precision is defined as no. of true positives divided by the no of true positives plus no of false positivies. . | Precision = TP/TP+FP . | . c). Recall or Sensitivity :- . Recall is a measure that tells us what proportion of patients that actually had cancer was diagnosed by the algorithm as having cancer. The actual positives (People having cancer are TP and FN) and the people diagnosed by the model having a cancer are TP. (Note: FN is included because the Person actually had a cancer even though the model predicted otherwise. | The ability of a model to find all the relevant cases within a dataset. Precise definition is number of true positivies divided by the number of true positivies plus the number of false negatives. . | Sensitivity = TP/TP+FN . | When to use Precision and When to use Recall?: . | It is clear that recall gives us information about a classifier’s performance with respect to false negatives (how many did we miss), while precision gives us information about its performance with respect to false positives(how many did we caught). . | Precision is about being precise. So even if we managed to capture only one cancer case, and we captured it correctly, then we are 100% precise. . | Recall is not so much about capturing cases correctly but more about capturing all cases that have “cancer” with the answer as “cancer”. So if we simply always say every case as “cancer”, we have 100% recall. . | So basically if we want to focus more on minimising False Negatives, we would want our Recall to be as close to 100% as possible without precision being too bad and if we want to focus on minimising False positives, then our focus should be to make Precision as close to 100% as possible. . | . d). Specificity :- . Specificity is a measure that tells us what proportion of patients that did NOT have cancer, were predicted by the model as non-cancerous. The actual negatives (People actually NOT having cancer are FP and TN) and the people diagnosed by us not having cancer are TN. (Note: FP is included because the Person did NOT actually have cancer even though the model predicted otherwise). . | Specificity = TN / FP + TN . | Specificity is the exact opposite of Recall . | . e). F1 - Score :- . We don’t really want to carry both Precision and Recall in our pockets every time we make a model for solving a classification problem. So it’s best if we can get a single score that kind of represents both Precision(P) and Recall(R). F1 score is nothing but harmonic mean. . | Harmonic mean is kind of an average when x and y are equal. But when x and y are different, then it’s closer to the smaller number as compared to the larger number. . | While recall expresses the ability to find all relevant instances in a dataset, precision expresses the proportion of the data points our model says was relevant actually were relevant. . | F1 Score = Harmonic Mean(Precision, Recall) . | F1 Score = 2 Precision Recall / (Precision + Recall) . | we use the harmonic mean instead of a simple average because it punishes extreme values. A classifier with precision of 1.0 and a recall of 0.0 has a simple average of 0.5 but an F1-score of 0 . | . So, we have seen confusion matrix with different metrics like accuracy, precision, recall, F1-score, specificity etc. . 2. AUC-ROC . 2. Regression Metrics . Regression is a task when a model attempts to predict continuous values. . 1. Mean Absolute Error (MAE) 2. Mean Squared Error (MSE) 3. Root Mean Squared Error (RMSE) . 1. Mean Absolute Error (MAE) . This is the mean of the absolute value or errors. $$ { frac{1}{N} sum_{i=1}^{N}(y_i - hat{y_i})} $$ . | MAE wont punish large errors . | . 2. Mean Squared Error (MSE) . This is the mean of squared error. Large error are noted more than MAE, making MSE more popular $$ { frac{1}{N} sum_{i=1}^{N}(y_i - hat{y_i})^2} $$ | . 3. Root Mean Squared Error(RMSE) and Root Mean Squared Log Error (RMSLE) . RMSE and RMSLE are used to find the difference between Actual output values(y) and predicted output values. . To understand these concepts and their differences, it is important to know what does Mean Squared Error (MSE) mean. MSE incorporates both the variance and the bias of the predictor(target column). RMSE is the square root of MSE. In case of unbiased estimator, RMSE is just the square root of variance, which is actually Standard Deviation. . Note: Square root of variance is standard deviation. . Equations of RMSE:- . $$ sqrt{ frac{1}{N} sum_{i=1}^{N}(y_i - hat{y_i})^2} $$ . Equation of RMSLE:- . $$ sqrt{ frac{1}{N} sum_{i=1}^{N}( log{(y_i)} - log{ hat{(y_i}))}^2} $$ . In case of RMSLE, you take the log of the predictions and actual values. So basically, what changes is the variance that you are measuring. I believe RMSLE is usually used when you don&#39;t want to penalize huge differences in the predicted and the actual values when both predicted and true values are huge numbers. . If both predicted and actual values are small: RMSE and RMSLE is same. | If either predicted or the actual value is big: RMSE &gt; RMSLE | If both predicted and actual values are big: RMSE &gt; RMSLE (RMSLE becomes almost negligible) | So, RMSLE measurement is not as widely used as MSE and MAE, but it is used as the metric for the Kaggle competition that uses the bike-sharing etc. dataset. It is, effectively, the RMSE of the log-transformed predicted and target values. This measurement is useful when there is a wide range in the target variable, and you do not necessarily want to penalize large errors when the predicted and target values are themselves high. It is also effective when you care about percentage errors rather than the absolute value of errors. . Lets have a look at the below example . Case a) : AV = 600, PV = 1000 . RMSE = 400, RMSLE = 0.5108 . Case b) : AV = 1400, PV = 1000 . RMSE = 400, RMSLE = 0.3365 . Here, AV = Actual Value, PV = Predicted Value . References:- . https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b |",
            "url": "https://smsrikanthreddy.github.io/blog/2021/05/03/Evaluation_Metrics.html",
            "relUrl": "/2021/05/03/Evaluation_Metrics.html",
            "date": " • May 3, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Links",
            "content": "My First markdown book . fastpages will automatically convert markdown files saved into this directory as blog posts! . You must save your notebook with the naming convention YYYY-MM-DD-*.md. Examples of valid filenames are: . here code snipts will reside . . Resources . Jekyll posts | Example markdown post | .",
            "url": "https://smsrikanthreddy.github.io/blog/2021/05/02/links.html",
            "relUrl": "/2021/05/02/links.html",
            "date": " • May 2, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Pandas Advanced Tutorial",
            "content": "Pandas Tutorial . import pandas as pd import numpy as np . from numpy.random import randn np.random.seed(42) . df = pd.DataFrame(randn(5, 4), index=&quot;A B C D E&quot;.split(), columns=&#39;W X Y Z&#39;.split()) df . W X Y Z . A 1.465649 | -0.225776 | 0.067528 | -1.424748 | . B -0.544383 | 0.110923 | -1.150994 | 0.375698 | . C -0.600639 | -0.291694 | -0.601707 | 1.852278 | . D -0.013497 | -1.057711 | 0.822545 | -1.220844 | . E 0.208864 | -1.959670 | -1.328186 | 0.196861 | . Reset index . # Reset to default 0,1...n index df.reset_index() . index W X Y Z . 0 A | 1.465649 | -0.225776 | 0.067528 | -1.424748 | . 1 B | -0.544383 | 0.110923 | -1.150994 | 0.375698 | . 2 C | -0.600639 | -0.291694 | -0.601707 | 1.852278 | . 3 D | -0.013497 | -1.057711 | 0.822545 | -1.220844 | . 4 E | 0.208864 | -1.959670 | -1.328186 | 0.196861 | . newind = &#39;CA NY WY OR CO&#39;.split() . df[&#39;States&#39;] = newind df . W X Y Z States . A 1.465649 | -0.225776 | 0.067528 | -1.424748 | CA | . B -0.544383 | 0.110923 | -1.150994 | 0.375698 | NY | . C -0.600639 | -0.291694 | -0.601707 | 1.852278 | WY | . D -0.013497 | -1.057711 | 0.822545 | -1.220844 | OR | . E 0.208864 | -1.959670 | -1.328186 | 0.196861 | CO | . df.set_index(&#39;States&#39;,inplace=True) df . W X Y Z . States . CA 1.465649 | -0.225776 | 0.067528 | -1.424748 | . NY -0.544383 | 0.110923 | -1.150994 | 0.375698 | . WY -0.600639 | -0.291694 | -0.601707 | 1.852278 | . OR -0.013497 | -1.057711 | 0.822545 | -1.220844 | . CO 0.208864 | -1.959670 | -1.328186 | 0.196861 | . Groupby . import pandas as pd # Create dataframe data = {&#39;Company&#39;:[&#39;GOOG&#39;,&#39;GOOG&#39;,&#39;MSFT&#39;,&#39;MSFT&#39;,&#39;FB&#39;,&#39;FB&#39;], &#39;Person&#39;:[&#39;Sam&#39;,&#39;Charlie&#39;,&#39;Amy&#39;,&#39;Vanessa&#39;,&#39;Carl&#39;,&#39;Sarah&#39;], &#39;Sales&#39;:[200,120,340,124,243,350]} df = pd.DataFrame(data) . df . Company Person Sales . 0 GOOG | Sam | 200 | . 1 GOOG | Charlie | 120 | . 2 MSFT | Amy | 340 | . 3 MSFT | Vanessa | 124 | . 4 FB | Carl | 243 | . 5 FB | Sarah | 350 | . df.groupby(&#39;Company&#39;) . &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000018A0C6A41D0&gt; . by_comp = df.groupby(&quot;Company&quot;) . by_comp.mean() . Sales . Company . FB 296.5 | . GOOG 160.0 | . MSFT 232.0 | . df.groupby(&#39;Company&#39;).mean() . Sales . Company . FB 296.5 | . GOOG 160.0 | . MSFT 232.0 | . by_comp.std() . Sales . Company . FB 75.660426 | . GOOG 56.568542 | . MSFT 152.735065 | . by_comp.min() . Person Sales . Company . FB Carl | 243 | . GOOG Charlie | 120 | . MSFT Amy | 124 | . by_comp.max() . Person Sales . Company . FB Sarah | 350 | . GOOG Sam | 200 | . MSFT Vanessa | 340 | . by_comp.count() . Person Sales . Company . FB 2 | 2 | . GOOG 2 | 2 | . MSFT 2 | 2 | . by_comp.describe() . Sales . count mean std min 25% 50% 75% max . Company . FB 2.0 | 296.5 | 75.660426 | 243.0 | 269.75 | 296.5 | 323.25 | 350.0 | . GOOG 2.0 | 160.0 | 56.568542 | 120.0 | 140.00 | 160.0 | 180.00 | 200.0 | . MSFT 2.0 | 232.0 | 152.735065 | 124.0 | 178.00 | 232.0 | 286.00 | 340.0 | . by_comp.describe().transpose() . Company FB GOOG MSFT . Sales count 2.000000 | 2.000000 | 2.000000 | . mean 296.500000 | 160.000000 | 232.000000 | . std 75.660426 | 56.568542 | 152.735065 | . min 243.000000 | 120.000000 | 124.000000 | . 25% 269.750000 | 140.000000 | 178.000000 | . 50% 296.500000 | 160.000000 | 232.000000 | . 75% 323.250000 | 180.000000 | 286.000000 | . max 350.000000 | 200.000000 | 340.000000 | . by_comp.describe().transpose()[&#39;GOOG&#39;] . Sales count 2.000000 mean 160.000000 std 56.568542 min 120.000000 25% 140.000000 50% 160.000000 75% 180.000000 max 200.000000 Name: GOOG, dtype: float64 . apply . df = pd.DataFrame({&#39;col1&#39;:[1,2,3,4],&#39;col2&#39;:[444,555,666,444],&#39;col3&#39;:[&#39;abc&#39;,&#39;def&#39;,&#39;ghi&#39;,&#39;xyz&#39;]}) df.head() . col1 col2 col3 . 0 1 | 444 | abc | . 1 2 | 555 | def | . 2 3 | 666 | ghi | . 3 4 | 444 | xyz | . def times2(x): return x*2 . df[&#39;col1&#39;].apply(times2) . 0 2 1 4 2 6 3 8 Name: col1, dtype: int64 . df[&#39;col3&#39;].apply(len) . 0 3 1 3 2 3 3 3 Name: col3, dtype: int64 . df[&#39;col1&#39;].sum() . 10 .",
            "url": "https://smsrikanthreddy.github.io/blog/jupyter/2021/05/01/Pandas-Advanced.html",
            "relUrl": "/jupyter/2021/05/01/Pandas-Advanced.html",
            "date": " • May 1, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Numpy Tutorial",
            "content": "Numpy Tutorial . ## import numpy import numpy as np . my_lst = [1, 2, 3] my_lst . [1, 2, 3] . np.array(my_lst) . array([1, 2, 3]) . my_matrix = [[1, 2, 3],[4, 5, 6],[7, 8, 9]] my_matrix . [[1, 2, 3], [4, 5, 6], [7, 8, 9]] . np.array(my_matrix) . array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) . Built-ins . np.arange(0,11) . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) . np.arange(0,11,2) . array([ 0, 2, 4, 6, 8, 10]) . Zeros and ones . np.zeros(3) . array([0., 0., 0.]) . np.zeros((3, 3)) . array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) . np.ones(3) . array([1., 1., 1.]) . np.ones((3, 3)) . array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . linspace . np.linspace(0, 10, 3) . array([ 0., 5., 10.]) . np.linspace(0,5,20) . array([0. , 0.26315789, 0.52631579, 0.78947368, 1.05263158, 1.31578947, 1.57894737, 1.84210526, 2.10526316, 2.36842105, 2.63157895, 2.89473684, 3.15789474, 3.42105263, 3.68421053, 3.94736842, 4.21052632, 4.47368421, 4.73684211, 5. ]) . eye . np.eye(4) . array([[1., 0., 0., 0.], [0., 1., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 1.]]) . Random . rand . np.random.rand(2) . array([0.40238536, 0.06656609]) . np.random.rand(5, 5) . array([[0.12254725, 0.348197 , 0.24849521, 0.47882429, 0.22543093], [0.97439097, 0.85104882, 0.21975901, 0.64904836, 0.15185813], [0.39898 , 0.87820818, 0.04461097, 0.26572141, 0.20420263], [0.18067849, 0.62212104, 0.9233101 , 0.91842698, 0.01005861], [0.22570714, 0.26014876, 0.72662577, 0.86396834, 0.53274278]]) . randn . np.random.randn(2) . array([-0.90371241, -0.79366858]) . np.random.randn(5, 5) . array([[ 1.44888877, 0.74329783, -1.38152915, -2.22003905, -2.11033026], [ 0.67312385, -0.01857065, -0.70392401, -0.6683721 , -0.51541829], [-0.10372972, -0.72184981, -0.19980393, -0.1513105 , 0.4171869 ], [ 0.36287574, 0.92669748, 0.25979809, -0.16400741, -0.80226408], [-1.14886478, 1.21948235, -0.0321742 , -0.58590923, 0.3878124 ]]) . randint . np.random.randint(1,100) . 10 . np.random.randint(1,100,10) . array([ 2, 74, 83, 63, 56, 22, 62, 31, 50, 58]) . seed . np.random.seed(42) np.random.rand(4) . array([0.37454012, 0.95071431, 0.73199394, 0.59865848]) . np.random.seed(42) np.random.rand(4) . array([0.37454012, 0.95071431, 0.73199394, 0.59865848]) . Array Attributes and Methods . arr = np.arange(25) ranarr = np.random.randint(0,50,10) . ranarr . array([38, 18, 22, 10, 10, 23, 35, 39, 23, 2]) . arr . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]) . Reshape . arr.reshape(5,5) . array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]]) . max, min, argmax, argmin . ranarr . array([38, 18, 22, 10, 10, 23, 35, 39, 23, 2]) . ranarr.max() . 39 . ranarr.min() . 2 . ranarr.argmax() . 7 . ranarr.argmin() . 9 . Shape . arr.shape . (25,) . # Notice the two sets of brackets arr.reshape(1,25) . array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]]) . arr.reshape(1,25).shape . (1, 25) . arr.reshape(25,1) . array([[ 0], [ 1], [ 2], [ 3], [ 4], [ 5], [ 6], [ 7], [ 8], [ 9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24]]) . arr.reshape(25,1).shape . (25, 1) . dtype . arr.dtype . dtype(&#39;int32&#39;) . arr2 = np.array([1.2, 3.4, 5.6]) arr2.dtype . dtype(&#39;float64&#39;) . Bracket Indexing and Selection . #Get a value at an index arr[8] . 8 . #Get values in a range arr[1:5] . array([1, 2, 3, 4]) . #Get values in a range arr[0:5] . array([0, 1, 2, 3, 4]) . Broadcasting . #Setting a value with index range (Broadcasting) arr[0:5]=100 #Show arr . array([100, 100, 100, 100, 100, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]) . # Reset array, we&#39;ll see why I had to reset in a moment arr = np.arange(0,11) #Show arr . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) . #Important notes on Slices slice_of_arr = arr[0:6] #Show slice slice_of_arr . array([0, 1, 2, 3, 4, 5]) . #Change Slice slice_of_arr[:]=99 #Show Slice again slice_of_arr . array([99, 99, 99, 99, 99, 99]) . arr . array([99, 99, 99, 99, 99, 99, 6, 7, 8, 9, 10]) . #To get a copy, need to be explicit arr_copy = arr.copy() arr_copy . array([99, 99, 99, 99, 99, 99, 6, 7, 8, 9, 10]) . Indexing a 2D array (matrices) . arr_2d = np.array(([5,10,15],[20,25,30],[35,40,45])) #Show arr_2d . array([[ 5, 10, 15], [20, 25, 30], [35, 40, 45]]) . #Indexing row arr_2d[1] . array([20, 25, 30]) . #Indexing 2nc column arr_2d[:,1] . array([10, 25, 40]) . # Format is arr_2d[row][col] or arr_2d[row,col] # Getting individual element value arr_2d[1][0] . 20 . # 2D array slicing #Shape (2,2) from top right corner arr_2d[:2,1:] . array([[10, 15], [25, 30]]) . #Shape bottom row arr_2d[2] . array([35, 40, 45]) . #Shape bottom row arr_2d[2,:] . array([35, 40, 45]) . Conditional Selection . arr = np.arange(1,11) arr . array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) . arr &gt; 4 . array([False, False, False, False, True, True, True, True, True, True]) . bool_arr = arr&gt;4 . bool_arr . array([False, False, False, False, True, True, True, True, True, True]) . arr[bool_arr] . array([ 5, 6, 7, 8, 9, 10]) . arr[arr&gt;2] . array([ 3, 4, 5, 6, 7, 8, 9, 10]) . Arithmetic . arr = np.arange(0, 11) arr . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) . arr + arr . array([ 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]) . arr * arr . array([ 0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100]) . arr - arr . array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) . # This will raise a Warning on division by zero, but not an error! # It just fills the spot with nan arr/arr . C: Users srmetlakunta AppData Roaming Python Python37 site-packages ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide &#34;&#34;&#34;Entry point for launching an IPython kernel. . array([nan, 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) . # Also a warning (but not an error) relating to infinity 1/arr . C: Users srmetlakunta AppData Roaming Python Python37 site-packages ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide . array([ inf, 1. , 0.5 , 0.33333333, 0.25 , 0.2 , 0.16666667, 0.14285714, 0.125 , 0.11111111, 0.1 ]) . arr**3 . array([ 0, 1, 8, 27, 64, 125, 216, 343, 512, 729, 1000], dtype=int32) . Universal Array Functions . # Taking Square Roots np.sqrt(arr) . array([0. , 1. , 1.41421356, 1.73205081, 2. , 2.23606798, 2.44948974, 2.64575131, 2.82842712, 3. , 3.16227766]) . # Calculating exponential (e^) np.exp(arr) . array([1.00000000e+00, 2.71828183e+00, 7.38905610e+00, 2.00855369e+01, 5.45981500e+01, 1.48413159e+02, 4.03428793e+02, 1.09663316e+03, 2.98095799e+03, 8.10308393e+03, 2.20264658e+04]) . # Trigonometric Functions like sine np.sin(arr) . array([ 0. , 0.84147098, 0.90929743, 0.14112001, -0.7568025 , -0.95892427, -0.2794155 , 0.6569866 , 0.98935825, 0.41211849, -0.54402111]) . # Taking the Natural Logarithm np.log(arr) . C: Users srmetlakunta AppData Roaming Python Python37 site-packages ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log . array([ -inf, 0. , 0.69314718, 1.09861229, 1.38629436, 1.60943791, 1.79175947, 1.94591015, 2.07944154, 2.19722458, 2.30258509]) . Axis Logic . arr_2d = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]]) arr_2d . array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]]) . arr_2d.sum(axis=0) #(columnwise) . array([15, 18, 21, 24]) . arr_2d.sum(axis=1) #(rowwise) . array([10, 26, 42]) .",
            "url": "https://smsrikanthreddy.github.io/blog/jupyter/2021/04/30/Numpy-Tutorial.html",
            "relUrl": "/jupyter/2021/04/30/Numpy-Tutorial.html",
            "date": " • Apr 30, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Math and Jupyter Commands",
            "content": "Here in this notebook, we will be looking into &quot;how to write math equations in jupyter notebook&quot;. The reason for writing this notebook is, I want to have all these instructions at once instaed of wrangling around different websites . Lets start with math equation . The math equation cell needs to be in Markdown mode . $ hat{y} = hat{ beta}_{0} + sum limits_{j=1} ^{p} X_{j} hat{ beta}_{j} $ . $ hat{y} = hat{ beta}_{0} + sum limits_{j=1} ^{p} X_{j} hat{ beta}_{j} $ . other math notations . - $ : All the Math you want to write in the markdown should be inside opening and closing $ symbol in order to be processed as Math. - beta : Creates the symbol beta - hat{} : A hat is covered over anything inside the curly braces of hat{}. E.g. in hat{Y} hat is created over Y and in hat{ beta}_{0}, hat is shown over beta - _{} : Creates as subscript, anything inside the curly braces after _. E.g. hat{ beta}_{0} will create beta with a hat and give it a subscript of 0. - ^{} : (Similar to subscript) Creates as superscript, anything inside the curly braces after ^. - sum : Creates the summation symbol - limits _{} ^{} : Creates lower and upper limit for the sum using the subscript and superscript notation. - *** : Creates horizontal line - &emsp; : Creates space. (Ref: Space in ‘markdown’ cell of Jupyter Notebook) - gamma : Creates gamma symbol - displaystyle : Forces display mode (BONUS 3 above). (Ref: Display style in Math mode) - frac{}{} : Creates fraction with two curly braces from numerator and denominator. - &lt;br&gt; : Creates line breaks - Bigg : Helps create parenthesis of big sizes. (Ref: Brackets and Parentheses) - partial : Creates partial derivatives symbol - underset() : To write under a text. E.g. gamma under arg min, instead of a subscript. In the algorithm you’ll see both types. - in : Creates belongs to symbol which is heavily used in set theory. . We can write Math inside two $$ as well. The difference is inline mode vs display mode. &quot;Inline mode is for math that is included within a line or paragraph of text, and display mode is for math that is set apart from the main text.&quot;&quot; . $$f&#39;(a) = lim_{x to a} frac{f(x) - f(a)}{x-a}$$ . $$f&#39;(a) = lim_{x to a} frac{f(x) - f(a)}{x-a}$$ . Latex . Common symbols . from IPython.display import Image Image(filename=&quot;/my_icons/latex/latex_common_symbols_1.png&quot;) . Image(filename=&quot;/my_icons/latex/latex_common_symbols_2.png&quot;) . Matrices and Brackets . Create a matrix without brackets: $$ begin{matrix} a &amp; b c &amp; d end{matrix}$$ . $$ begin{matrix} a &amp; b c &amp; d end{matrix}$$ . Create a matrix with round brackets: $$ begin{pmatrix} a &amp; b c &amp; d end{pmatrix}$$ . $$ begin{pmatrix} a &amp; b c &amp; d end{pmatrix}$$ . Create a matrix with square brackets: $$ begin{bmatrix} 1 &amp; 2 &amp; 1 3 &amp; 0 &amp; 1 0 &amp; 2 &amp; 4 end{bmatrix}$$ . $$ begin{bmatrix} 1 &amp; 2 &amp; 1 3 &amp; 0 &amp; 1 0 &amp; 2 &amp; 4 end{bmatrix}$$ . Use left and right to enclose an arbitrary expression in brackets: $$ left( frac{p}{q} right)$$ . $$ left( frac{p}{q} right)$$ . Jupyter Commands . 1. Text Commands . *emphasis*, **strong**, &#39;code&#39; . emphasis, strong,code . &lt;b&gt;This is bold text &lt;/b&gt; ** This is bold text --This is bold text . This is bold text . **This is bold text . __ This is bold text . 2. Headings . # H1 ## H2 ### H3 #### H4 ##### H5 ###### H6 . H1 . H2 . H3 . H4 . H5 . H6 . 3. Lists . 1. Number theory 2. Algebra 3. Partial differential equations 4. Probability . Number theory | Algebra | Partial differential equations | Probability | Create an unordered list using an asterisk * for each item . * Number theory * Algebra * Partial differential equations * Probability . Number theory | Algebra | Partial differential equations | Probability | . - Fish - Eggs - Cheese . Fish | Eggs | Cheese | . &lt;ul&gt; &lt;li&gt;Fish&lt;/li&gt; &lt;li&gt;Eggs&lt;/li&gt; &lt;li&gt;Cheese&lt;/li&gt; &lt;/ul&gt; . Fish | Eggs | Cheese | . Use indentation to create nested lists . 1. Mathematics * Calculus * Linear Algebra * Probability 2. Physics * Classical Mechanics * Relativity * Thermodynamics 3. Biology * Diffusion and Osmosis * Homeostasis * Immunology . Mathematics Calculus | Linear Algebra | Probability | . | Physics Classical Mechanics | Relativity | Thermodynamics | . | Biology Diffusion and Osmosis | Homeostasis | Immunology | . | 4. Tables . | Python Operator | Description | | :: | :: | | `+` | addition | | `-` | subtraction | | `*` | multiplication | | `/` | division | | `**` | power | . Python Operator Description . + | addition | . - | subtraction | . * | multiplication | . / | division | . ** | power | . #### 5. Links # #[description](url) # #[[UBC Math](http://www.math.ubc.ca)] . #### 6. Images # #![description](url) # #![preview](./my_icons/fastai_logo.png) . References . https://medium.com/analytics-vidhya/writing-math-equations-in-jupyter-notebook-a-naive-introduction-a5ce87b9a214 | https://www.math.ubc.ca/~pwalls/math-python/jupyter/latex/ | https://www.datacamp.com/community/tutorials/markdown-in-jupyter-notebook |",
            "url": "https://smsrikanthreddy.github.io/blog/jupyter/2021/04/17/Math-and-Jupyter-commands-in-Notebook.html",
            "relUrl": "/jupyter/2021/04/17/Math-and-Jupyter-commands-in-Notebook.html",
            "date": " • Apr 17, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Neural Collaborative Filtering",
            "content": "Where do we use Neural Collborative Filtering (NCF) Algorithm . In recommendation systems, mainly in ecommerce websites, we see recommendations when we search for a product. The algorithm for recommending items for a customer is chaning/improving based on customer choices, personalized recommendation etc from time to time. So to serve customers more accurately by predicting best choices of items based on customers likes, personalized views, tastes, geographical likes etc we are using Neural Collaborative Filtering . Before going throught the NCF, lets discuss the most successfull algorithm Matrix Factorization, its usecases and drawbacks. Why NCF is better at recommedning the items based on other user likes, location etc. . Matrix Factorization . Matrix factorization represents user/item as a vector of latent features which are projected into a shared feature space. In this feature space, the user-item interactions could be modeled using the inner product of user-item latent vectors. This vanilla implementation of Matrix factorization can be enhanced by integrating it with neighbor-based models, combining it with topic models of item content and extending it to factorization machines for general modeling of feature. . Equation 1 :- $$ hat{Y}_{u,i} = f(u,i|{ theta}) $$ . $y_{u,i}$: predicted score for interaction between user u and item i &lt;br&gt; ${ theta}$: model parameters &lt;br&gt; $f(Interaction Function)$: maps model parameters to the predicted score . In order to calculate theta, an objective function needs to be optimized. The 2 most popular loss functions for the recommendation system are a pointwise and pairwise loss. . Matrix factorization models the user-item interactions through a scalar product of user-item latent vectors. In mathematical terms, it is represented as follows . Equation 2 :- $$ hat{Y}_{u,i} = f(u,i|P_{u},q_{i}) = p^{T}_{u}q_{i} $ = $ sum_{k=1}^{K}p_{uk} q_{ik}$$ . $y_{u,i}$: predicted score for interaction between user u and item i $p_{u} $: latent vector for user u $q_{i}$: latent vector for item K: the dimension of latent space . Despite the effectiveness of matrix factorization for collaborative filtering, it’s performance is hindered by the simple choice of interaction function - inner product. Its performance can be improved by incorporating user-item bias terms into the interactiion function. This proves that the simple multiplication of latent features (inner product), may not be sufficient to capture the complex structure of user interaction data. . As we can see, MF models the two-way interaction of user and item latent factors, assuming each dimension of the latent space is independent of each other and linearly combining them with the same weight. As such, MF can be deemed as a linear model of latent factors . from IPython.display import Image Image(filename=&quot;./my_icons/NCF/MF_Limitation.png&quot;) . Figure 1: An example illustrates MF’s limitation. From data matrix (a), u4 is most similar to u1, followed by u3, and lastly u2. However in the latent space (b), placing p4 closest to p1 makes p4 closer to p2 than p3 , incurring a large ranking loss. . Figure 1 illustrates how the inner product function can limit the expressiveness of MF. There are two settings to be stated clearly beforehand to understand the example well. First, since MF maps users and items to the same latent space, the similarity between two users can also be measured with an inner product, or equivalently2 , the cosine of the angle between their latent vectors. Second, without loss of generality, we use the Jaccard coefficient3 as the ground truth similarity of two users that MF needs to recover. The above figure shows the possible limitation of MF caused by the use of a simple and fixed inner product to estimate complex user–item interactions in the low-dimensional latent space. We note that one way to resolve the issue is to use a large number of latent factors K. However, it may adversely hurt the generalization of the model (e.g., overfitting the data), especially in sparse settings [26]. In this work, we address the limitation by learning the interaction function using Deep Neural Networks from data . Implicit Feedback Indirectly reflects the user’s preference through watching videos, product purchases, and clicks. The advantage of using implicit feedback is that it is easier to collect and is in surplus. The disadvantage is that there no readily available negative feedback. Explicit Feedback consists of ratings and reviews. It’s a direct feedback and the negative feedback or the likeliness of a product is readily available in terms of rating. . What is Collaborative Filtering . Collaborative filtering is a technique that can filter out items that a user might like on the basis of reactions by similar users. It works by searching a large group of people and finding a smaller set of users with tastes like a particular user. It looks at the items they like and combines them to create a ranked list of suggestions. Collaborative filtering helps in identifying features between user and item using matrix - factorization by applying inner product on the latent features of users and items. . Despite the effectiveness of matrix factorization for collaborative filtering, its performance is hindered by the simple choice of interaction function - inner product. Its performance can be improved by incorporating user-item bias terms into the interaction function. This proves that the simple multiplication of latent features (inner product), may not be sufficient to capture the complex structure of user interaction data. This calls for designing a better, dedicated interaction function for modeling the latent feature interaction between users and items. Neural Collaborative Filtering (NCF) aims to solve this by: - . Modeling user-item feature interaction through neural network architecture. It utilizes a Multi-Layer Perceptron (MLP) to learn user-item interactions. This is an upgrade over MF as MLP can (theoretically) learn any continuous function and has high level of nonlinearities (due to multiple layers) making it well-endowed to learn user-item interaction function. . | Generalizing and expressing MF as a special case of NCF. As MF is highly successful in the recommendation domain, doing this will give more credence to NCF. . | NCF Architecture . Image(filename=&quot;./my_icons/NCF/ncf_architecture.png&quot;) . Input Layer binarise a sparse vector for a user and item identification where: Item (i): 1 means the user u has interacted with Item(i) User (u): To identify the user | Embedding layer is a fully connected layer that projects the sparse representation to a dense vector. The obtained user/item embeddings are the latent user/item vectors. | Neural CF layers use Multi-layered neural architecture to map the latent vectors to prediction scores. | The final output layer returns the predicted score by minimizing the pointwise loss/pairwise loss. | NCF modifies equation 1 in the following way: . Image(filename=&quot;./my_icons/NCF/NCF_equation_3.png&quot;) . where P: Latent factor matrix for users (Size=M K) Q: Latent factor matrix for items (Size=N K) Theta(f): Model parameters Since f is formulated as MLP it can be expanded a . Image(filename=&quot;./my_icons/NCF/NCF_equation_4.png&quot;) . Modeling user-item interaction . where Psi (out): mapping function for the output layer Psi (x): mapping function for the x-th neural collaborative filtering layer Equation 4 acts as the scoring function for NCF. . NCF&#8217;s loss function . Pointwise squared loss equation is represented as . Image(filename=&quot;./my_icons/NCF/NCF_equation_5.png&quot;) . loss function here y: observed interaction in Y y negative: all/sample of unobserved interactions w(u,i): the weight of training instance (hyperparameter) . The squared loss can be explained if we assume that the observations are from a Gaussian distribution which in our case is not true. Plus the prediction score y_carat should return a score between [0,1] to represent the likelihood of the given user-item interaction. In short, we need a probabilistic approach for learning the pointwise NCF that pays special attention to the binary property of implicit data. . NCF uses a logistic /probit function at the output layer to solve for the above.With the above settings, the likelihood function is defined as : . Image(filename=&quot;./my_icons/NCF/NCF_equation_6.png&quot;) . negative log of the likelihood function . Image(filename=&quot;./my_icons/NCF/NCF_equation_7.png&quot;) . By employing a probabilistic treatment, NCF transforms the recommendation problem to a binary classification problem To account for negative instances y- is uniformly sampled from the unobserved interactions. . Generalized Matrix Factorization (GMF) . We now show how MF can be interpreted as a special case of our NCF framework. As MF is the most popular model for recommendation and has been investigated extensively in literature, being able to recover it allows NCF to mimic a large family of factorization models. Due to the one-hot encoding of user (item) ID of the input layer, the obtained embedding vector can be seen as the latent vector of user (item). Let the user latent vector pu be P T v U u and item latent vector qi be QT v I i . We define the mapping function of the first neural CF layer as, . Image(filename=&quot;./my_icons/NCF/NCF_equation_8.png&quot;) . here a-out: activation function h: edge weights of the output layer We can play with a-out and h to create multiple variations of GMF. . Image(filename=&quot;./my_icons/NCF/NCF_table.png&quot;) . As you can see from the above table that GMF with identity activation function and edge weights as 1 is indeed MF. The other 2 variations are expansions on the generic MF. The last variation of GMF with sigmoid as activation is used in NCF. NCF uses GMF with sigmoid as the activation function and learns h (the edge weights) from the data with log loss. . Multi-Layer Perceptron (MLP) . NCF is an example of multimodal deep learning as it contains data from 2 pathways namely user and item. The most intuitive way to combine them is by concatenation. But a simple vector concatenation does not account for user-item interactions and is insufficient to model the collaborative filtering effect. To address this NCF adds hidden layers on top of concatenated user-item vectors(MLP framework), to learn user-item interactions. This endows the model with a lot of flexibility and non-linearity to learn the user-item interactions. This is an upgrade over MF that uses a fixed element-wise product on them. More precisely, the MLP alter Equation 1 as follows . Image(filename=&quot;./my_icons/NCF/NCF_equation_9.png&quot;) . where: W(x): Weight matrix b(x): bias vector a(x): activation function for the x-th layer’s perceptron p: latent vector for the user q: latent vector for an item . NCF uses ReLU as an activation function for its MLP part. Due to multiple hidden layers, the model has sufficient complexity to learn user-item interactions as compared to the fixed element-wise product of their latent vectors (MF way). . Fusion of GMF and MLP . So far we have developed two instantiations of NCF — GMF that applies a linear kernel to model the latent feature interactions, and MLP that uses a non-linear kernel to learn the interaction function from data. The question then arises: how can we fuse GMF and MLP under the NCF framework. . NCF combines these models together to superimpose their desirable characteristics. NCF concatenates the output of GMF and MLP before feeding them into NeuMF layer. . Image(filename=&quot;./my_icons/NCF/fusion.png&quot;) . Important points to notice . GMF/MLP have separate user and item embeddings. This is to make sure that both of them learn optimal embeddings independently. | GMF replicates the vanilla MF by element-wise product of the user-item vector. | MLP takes the concatenation of user-item latent vectors as input. | The outputs of GMF and MLP are concatenated in the final NeuMF (Neural Matrix Factorization) layer. | The score function of equation 1 is modeled as, . Image(filename=&quot;./my_icons/NCF/fusion_equation.png&quot;) . G: GMF M: MLP p: User embedding q: Item embedding . We use ReLU as the activation function of MLP layers. This model combines the linearity of MF and non-linearity of DNNs for modelling user–item latent structures. We dub this model “NeuMF”, short for Neural Matrix Factorization. . Due to the non-convex objective function of NeuMF, gradient-based optimization methods can only find locally-optimal solutions. This could be solved by good weight initializations. To solve this NCF initializes GMF and MLP with pre-trained models. There are 2 ways to do this . Random Initialization . | Train GMF+MLP with random initializations until convergence. . | Use model parameters of 1 to initialize NCF. | The weights of the two models are concatenated for the output layer as . | GMF + MLP from scratch . | Image(filename=&quot;./my_icons/NCF/gmf_mlp.png&quot;) . where h(GMF): h vector of the pre-trained GMF h(MLP): h vector of the pre-trained MLP alpha: Hyper-parameter determining the trade-off between the 2 pre-trained models . GMF + MLP from scratch . | Adaptive Moment Estimation (Adam) adapts the learning rate for each parameter by performing smaller updates for frequent and larger updates for infrequent parameters. The Adam method yields faster convergence for both models than the vanilla SGD and relieves the pain of tuning the learning rate. . | After feeding pre-trained parameters into NeuMF, we optimize it with the vanilla SGD, rather than Adam. Adam needs to save momentum information for updating parameters. As the initialization with pre-trained networks does not store momentum information . |",
            "url": "https://smsrikanthreddy.github.io/blog/jupyter/2021/04/15/Neural-Collaborative-Filtering.html",
            "relUrl": "/jupyter/2021/04/15/Neural-Collaborative-Filtering.html",
            "date": " • Apr 15, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Evaluation Metrics",
            "content": "Introduction . why metrics are important . Metrics are important to evaluate models. To build better models by evaluating. | Metrics help capture business goals into quantitative target (not all errors are equal) | Metrics will help the teams effort into an definitive target/goal | Usefull to quantify the gap between, Desired performance and baseline | Desired performance and current performance | Measure progress over time | . | Useful for lower level tasks and debugging (e.g. diagnosing bias vs variance). | Ideally training objective should be the metric, but not always possible. Still, metrics are useful and important for evaluation. | . | Types of metrics There are two types of evaluation metrics, score based metrics (SVM-Regression, Linear Regression), threshold based metrics (SVM-Classification, Decision trees, Logistic Regression) | . | Different Evaluation Metrics . 1. Confusion Matrix . 2. F1 Score . 3. AUC-ROC . 4. Log Loss . 5. Gini Coefficient . 6. Root Mean Squared Error . | 1. Confusion Matrix . from IPython.display import Image Image(filename=&quot;./my_icons/Evaluation_Metrics/Srikanth_Confusion_Matrix_Diag.png&quot;) . Confusion Matrix is a performance measurement for machine learning classification. A confusion matrix is a NXN matrix, where N is the number of classes being predicted. For the above figure, we have N=2, and hence we get 2X2 matrix. Here are a few definitions, . TP : You have predicted positive and actual value is true | FP : You have predicted positive and actual value is false also called Type-1 Error | FN : You have predicted negative and actual value is true also called Type-2 Error | TN : You have predicted negative and actual value is false | . Accuracy : Out of all the classes, how much we predicted correctly. Total number of predictions which are correct. begin{equation*} frac{TP+TN}{TP+FP+TN+FN} end{equation*} | Precision : Out of all the positive classes we have predicted correctly, how many are actually positive begin{equation*} frac{TP}{TP+FP} end{equation*} | Recall (Sensitivity/True Positive Rate) : Out of all the true positive classes, how much we predicted correctly. It should be high as possible. begin{equation*} frac{TP}{TP+FN} end{equation*} | Specificity / True Negative Rate : Specificity tells us what proportion of the negative class got correctly classified.. It should be high as possible. begin{equation*} frac{TN}{TN+FP} end{equation*} | Fallout : Ratio of False Positive by False Positive and True Negative begin{equation*} frac{FP}{FP+TN} end{equation*} | False Negative Rate : False Negative Rate (FNR) tells us what proportion of the positive class got incorrectly classified by the classifier begin{equation*} frac{FN}{FN+TP} end{equation*} | . 2. F1 Score . It is difficult to compare two models with low precision and high recall or vice versa. So to make them comparable, we use F-Score. F-score helps to measure Recall and Precision at the same time. It uses Harmonic Mean in place of Arithmetic Mean by punishing the extreme values more. begin{equation*} frac{2*Precision*Recall}{Precision+Recall} end{equation*} | . 3. AUC-ROC . The biggest advantage of using ROC curve is that it is independent of the change in proportion of responders. | AUC-ROC curve helps us visualize how well our machine learning classifier is performing. Although it works for only binary classification problems. . (Area Under the Receiver operating characteristic) | . First lets discuss about the ROC . | . Sensitivity : What proportion of positive class got correctly classified. | Specificity : what proportion of the negative class got correctly classified | . First lets try to understand ROC (Receiver operating characteristic) curve. If we look at the confusion matrix below, we observe that for a probabilistic model, we get different value for each metric. . Image(filename=&quot;./my_icons/Evaluation_Metrics/Confusion_matrix.png&quot;) . Hence, for each sensitivity, we get a different specificity.The two vary as follows: . Image(filename=&quot;./my_icons/Evaluation_Metrics/sensitivity_specifitity_curves.png&quot;) . The ROC curve is the plot between sensitivity and (1- specificity). (1- specificity) is also known as false positive rate and sensitivity is also known as True Positive rate. Following is the ROC curve for the case in hand. . Image(filename=&quot;./my_icons/Evaluation_Metrics/ROC.png&quot;) . Let’s take an example of threshold = 0.5 (refer to confusion matrix). Here is the confusion matrix : . Image(filename=&quot;./my_icons/Evaluation_Metrics/Confusion_matrix2-150x129.png&quot;) . As you can see, the sensitivity at this threshold is 99.6% and the (1-specificity) is ~60%. This coordinate becomes one point in our ROC curve. To bring this curve down to a single number, we find the area under this curve (AUC). . Note that the area of entire square is 1*1 = 1. Hence AUC itself is the ratio under the curve and the total area. For the case in hand, we get AUC ROC as 96.4%. Following are a few thumb rules: . 90-1 = excellent (A) | 80-.90 = good (B) | 70-.80 = fair (C) | 60-.70 = poor (D) | 50-.60 = fail (F) | . We see that we fall under the excellent band for the current model. But this might simply be over-fitting. In such cases it becomes very important to in-time and out-of-time validations. . Points to Remember: . For a model which gives class as output, will be represented as a single point in ROC plot. . | Such models cannot be compared with each other as the judgement needs to be taken on a single metric and not using multiple metrics. For instance, model with parameters (0.2,0.8) and model with parameter (0.8,0.2) can be coming out of the same model, hence these metrics should not be directly compared. . | In case of probabilistic model, we were fortunate enough to get a single number which was AUC-ROC. But still, we need to look at the entire curve to make conclusive decisions. It is also possible that one model performs better in some region and other performs better in other. . | 4. Log-Loss . AUC ROC considers the predicted probabilities for determining our model’s performance. However, there is an issue with AUC ROC, it only takes into account the order of probabilities and hence it does not take into account the model’s capability to predict higher probability for samples more likely to be positive. In that case, we could us the log loss which is nothing but negative average of the log of corrected predicted probabilities for each instance. | Logarithmic Loss (Log Loss) | Rewards confident correct answers, heavily | penalizes confident wrong answers | . Image(filename=&quot;./my_icons/Evaluation_Metrics/log-loss.png&quot;) . p(yi) is predicted probability of positive class | 1-p(yi) is predicted probability of negative class | yi = 1 for positive class and 0 for negative class (actual values) | . References :- . http://cs229.stanford.edu/notes2020fall/notes2020fall/EvaluationMetrics.pdf | https://www.analyticsvidhya.com/blog/2019/08/11-important-model-evaluation-error-metrics/ | https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234 |",
            "url": "https://smsrikanthreddy.github.io/blog/jupyter/2020/11/30/Evaluation_Metrics.html",
            "relUrl": "/jupyter/2020/11/30/Evaluation_Metrics.html",
            "date": " • Nov 30, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Principal Component Analysis",
            "content": "Introduction . PCA forms the basis for any ML enthusiasits. It helps in reducing the number of features by keeping almost all the data within its components . Put simply, PCA involves making a coordinate transformation (i.e. rotation) from the arbitrary axes (or &quot;features&quot;) you started with to set of axes &#39;aligned with the data itself,&#39; and doing this almost always means that you can get rid of few of these &quot;components&quot; of data that have small variance without suffering much in the way of accuracy while saving tons of computation . what we&#39;ll learn . We&#39;ll define the following terms as we go, but here&#39;s the process in a nutshell: . Covariance: Find the covariance matrix for your dataset Eigenvectors: Find the eigenvectors of that matrix (these are the &quot;components&quot; btw) Ordering: Sort the eigenvectors/&#39;dimensions&#39; from biggest to smallest variance Projection / Data reduction: Use the eigenvectors corresponding to the largest variance to project the dataset into a reduced- dimensional space (Check: How much did we lose by that truncation?) . Covariance . If you got two data dimensions, and they vary together, then they are co-variant . STEP BY STEP EXPLANATION OF PCA . STEP 1: STANDARDIZATION . standardization is one of the important step before doing PCA or any ML problem. There could be columns whose values could be in range of 0 to 1 or 100 to 1000. so that the domination of features whose range is 100 to 1000 is more compared to 0 to 1. . The standardization is done using the below formula. . Mathematically it is done by subtracting the mean and dividing by the standard deviation for each feature. . begin{equation*} z = frac{value - mean}{standard deviation} end{equation*} Once the standardization is done, all the variables will be transformed to the same scale. . STEP 2: COVARIANCE MATRIX COMPUTATION . The aim of this step is to understand how the variables of the input data set are varying from the mean with respect to each other, or in other words, to see if there is any relationship between them. Because sometimes, variables are highly correlated in such a way that they contain redundant information. So, in order to identify these correlations, we compute the covariance matrix. . The covariance matrix is a p × p symmetric matrix (where p is the number of dimensions) that has as entries the covariances associated with all possible pairs of the initial variables. For example, for a 3-dimensional data set with 3 variables x, y, and z, the covariance matrix is a 3×3 matrix of this from: . from IPython.display import Image Image(filename=&quot;./my_icons/PCA/PrincipalComponentAnalysiCovarianceMatrix.png&quot;) . Since the covariance of a variable with itself is its variance (Cov(a,a)=Var(a)), in the main diagonal (Top left to bottom right) we actually have the variances of each initial variable. And since the covariance is commutative (Cov(a,b)=Cov(b,a)), the entries of the covariance matrix are symmetric with respect to the main diagonal, which means that the upper and the lower triangular portions are equal. . What do the covariances that we have as entries of the matrix tell us about the correlations between the variables? . It’s actually the sign of the covariance that matters : . . if positive then : the two variables increase or decrease together (correlated) . if negative then : One increases when the other decreases (Inversely correlated) . Now, that we know that the covariance matrix is not more than a table that summaries the correlations between all the possible pairs of variables, let’s move to the next step . STEP 3: COMPUTE THE EIGENVECTORS AND EIGENVALUES OF THE COVARIANCE MATRIX TO IDENTIFY THE PRINCIPAL COMPONENTS . Eigenvectors and eigenvalues are the linear algebra concepts that we need to compute from the covariance matrix in order to determine the principal components of the data . Principal components are new variables that are constructed as linear combinations or mixtures of the initial variables. These combinations are done in such a way that the new variables (i.e., principal components) are uncorrelated and most of the information within the initial variables is squeezed or compressed into the first components. So, the idea is 10-dimensional data gives you 10 principal components, but PCA tries to put maximum possible information in the first component, then maximum remaining information in the second and so on . Organizing information in principal components this way, will allow you to reduce dimensionality without losing much information, and this by discarding the components with low information and considering the remaining components as your new variables. . An important thing to realize here is that, the principal components are less interpretable and don’t have any real meaning since they are constructed as linear combinations of the initial variables . Geometrically speaking, principal components represent the directions of the data that explain a maximal amount of variance, that is to say, the lines that capture most information of the data. The relationship between variance and information here, is that, the larger the variance carried by a line, the larger the dispersion of the data points along it, and the larger the dispersion along a line, the more the information it has. To put all this simply, just think of principal components as new axes that provide the best angle to see and evaluate the data, so that the differences between the observations are better visible . Step 4: HOW PCA CONSTRUCTS THE PRINCIPAL COMPONENTS? . The First Principal Component has the largest variance of the data. It projects most of the data points on its line. Second Principal Component is uncorelated to the first principal and perpendicular to it also and it accounts for the next highest variance and this continues. Or mathematically speaking, it’s the line that maximizes the variance (the average of the squared distances from the projected points (red dots) to the origin). This continues until a total of p principal components have been calculated, equal to the original number of variables . Now that we understood what we mean by principal components, let’s go back to eigenvectors and eigenvalues. What you firstly need to know about them is that they always come in pairs, so that every eigenvector has an eigenvalue. And their number is equal to the number of dimensions of the data. For example, for a 3-dimensional data set, there are 3 variables, therefore there are 3 eigenvectors with 3 corresponding eigenvalues. . Without further ado, it is eigenvectors and eigenvalues who are behind all the magic explained above, because the eigenvectors of the Covariance matrix are actually the directions of the axes where there is the most variance(most information) and that we call Principal Components. And eigenvalues are simply the coefficients attached to eigenvectors, which give the amount of variance carried in each Principal Component. . By ranking your eigenvectors in order of their eigenvalues, highest to lowest, you get the principal components in order of significance. . Example: . let’s suppose that our data set is 2-dimensional with 2 variables x,y and that the eigenvectors and eigenvalues of the covariance matrix are as follows: . Image(filename=&quot;./my_icons/PCA/eigen_vectors.png&quot;) . If we rank the eigenvalues in descending order, we get λ1&gt;λ2, which means that the eigenvector that corresponds to the first principal component (PC1) is v1 and the one that corresponds to the second component (PC2) isv2. . After having the principal components, to compute the percentage of variance (information) accounted for by each component, we divide the eigenvalue of each component by the sum of eigenvalues. If we apply this on the example above, we find that PC1 and PC2 carry respectively 96% and 4% of the variance of the data. . Step 5: Feature Vector . In this step we choose to keep all or some of the principal components. Generally we discard low eigen values components to create a reduced matrix of input called Feature Vector. This we call as dimensionality reduced matrix and the technique is called dimensionality reduction technique . So, the feature vector is simply a matrix that has as columns the eigenvectors of the components that we decide to keep. This makes it the first step towards dimensionality reduction, because if we choose to keep only p eigenvectors (components) out of n, the final data set will have only p dimensions . To form the principal components for compuation, we take the transpose of the feature vector and left-multiply it with the transpose of scaled version of original dataset. . NewData = FeatureVector^T x ScaledData^T . Here, . NewData is the Matrix consisting of the principal components, . FeatureVector is the matrix we formed using the eigenvectors we chose to keep, and . ScaledData is the scaled version of original dataset . (‘T’ in the superscript denotes transpose of a matrix which is formed by interchanging the rows to columns and vice versa. In particular, a 2x3 matrix has a transpose of size 3x2) . References :- . https://builtin.com/data-science/step-step-explanation-principal-component-analysis | https://drscotthawley.github.io/PCA-From-Scratch/ | https://www.dezyre.com/data-science-in-python-tutorial/principal-component-analysis-tutorial |",
            "url": "https://smsrikanthreddy.github.io/blog/jupyter/2020/06/08/PCA.html",
            "relUrl": "/jupyter/2020/06/08/PCA.html",
            "date": " • Jun 8, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://smsrikanthreddy.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://smsrikanthreddy.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}